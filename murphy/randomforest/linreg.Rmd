---
title: "R Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

```{r setup}
library(randomForest)
library(MASS)
library(caret)

setwd("E:/Google Drive/School/W2022/STAT 441/kaggle/stat441_w22_kaggle_project/murphy/randomforest")

train <- read.csv("../../data/train.csv")
predict_set <- read.csv("../../data/test.csv")
predict_set$health <- rep(NA, NROW(predict_set))

fullset <- rbind(train, predict_set)

Mode <- function(x, na.rm = T) {
  if(na.rm){
    x = x[!is.na(x)]
  }

  ux <- unique(x)
  return(ux[which.max(tabulate(match(x, ux)))])
}

cross_entropy <- function (predict, obs_class) {
  # predict is a matrix, obs_class vector of class {1..M}
  N <- NROW(predict)
  sum = 0
  for (i in 1:N) {
    sum = sum + log(predict[i, obs_class[i]])
  }
  return(-(sum/N))
}
```

find rows columns with > 50% NA

```{r cleanup}
# % NA per column
missing_pct <- apply(train, 2, function(col) {sum(is.na(col))/NROW(col)})

# 1081 cols with more than 20% NA
sum(missing_pct >= 0.2)

# remove cols with more than 80% NA (20% cutoff)
fullset <- fullset[, missing_pct <= 0.2]

factors <- as.vector(read.table("../factor.txt", header=F))
factors <- factors[[1]]

selected_factors <- factors[factors %in% colnames(fullset)]

# as.factor factors 
fullset[selected_factors] <- lapply(fullset[selected_factors] , as.factor)

# replacing NAs with mode for factors, mean for numeric
M <- NCOL(fullset)
train <- data.frame(lapply(fullset[1:NROW(train),], function(x) {
    if(is.factor(x)) replace(x, is.na(x), Mode(na.omit(x)))
    else if(is.numeric(x)) replace(x, is.na(x), mean(x, na.rm=TRUE))
    else x
}))
predict_set <- data.frame(lapply(fullset[(NROW(train)+1):NROW(fullset), 1:(M-1)], function(x) {
    if(is.factor(x)) replace(x, is.na(x), Mode(na.omit(x)))
    else if(is.numeric(x)) replace(x, is.na(x), mean(x, na.rm=TRUE))
    else x
}))
```

```{r model_fit, cache = T}
#Dividing data into training and test set
#Random sampling 
samplesize = 0.60*nrow(train)
set.seed(100)
index = sample(seq_len(nrow(train)), size = samplesize)
#Creating training and test set 
datatrain = train[index,]
datatest = train[-index,]

#Build ordinal logistic regression model
model <- randomForest(health ~ . - uniqueid - year - personid, data = datatrain, proximity = T)
print(model)
summary(model)
```

```{r var_analysis}
library(ggplot2)

# find important variables
imp <- importance(model)
imp_df <- data.frame(
  vars = rownames(imp),
  coef = imp
)
imp_df <- imp_df[rev(order(imp_df$MeanDecreaseGini)),]

#write.csv(imp_df, "importance.csv", row.names = F)

p<-ggplot(data=imp_df[1:50,], aes(x=reorder(var, MeanDecreaseGini), y=MeanDecreaseGini)) +
  geom_bar(stat="identity") +
  xlab("Predictor") +
  ylab("Importance (MeanDecreaseGini)") +
  coord_flip()
  
p
```

```{r predict}
p1 <- predict(model, datatest, type = "prob")
#p2 <- predict(model, predict_set, type="prob")

# transform predict test set
#var_subset <- colnames(train)[-NROW(colnames(train))]
#predict_set <- predict_set[, var_subset]
#predict_set[selected_factors[-10]] <- lapply(predict_set[selected_factors[-10]] , as.factor)
#predict_set <- data.frame(lapply(predict_set, function(x) {
#    if(is.factor(x)) replace(x, is.na(x), Mode(na.omit(x)))
#    else if(is.numeric(x)) replace(x, is.na(x), mean(x, na.rm=TRUE))
#    else x
#}))

prediction <- predict(model, predict_set,type = "prob")
out.df <- as.data.frame(prediction)
out.df <- cbind(predict_set$uniqueid, out.df)
colnames(out.df) <- c("uniqueid", "p1", "p2", "p3", "p4", "p5")
write.csv(out.df, "prediction.csv", row.names = F)
```

# attempt 2

Variable selection based on top 50% most important variables

```{r attempt2_setup}
pos <- with(imp_df, which.min(abs(imp_df$MeanDecreaseGini - median(imp_df$MeanDecreaseGini))))
selected <- c(imp_df[1:(pos-1),]$var, 'health')

train <- train[, selected]
predict_set <- predict_set[, selected[-length(selected)]]

#Random sampling 
samplesize = 0.70*nrow(train)
set.seed(100)
index = sample(seq_len(nrow(train)), size = samplesize)
#Creating training and test set 
datatrain = train[index,]
datatest = train[-index,]

model <- randomForest(health ~ . , data = datatrain, proximity = T)

p1 <- predict(model, datatest, type = "prob")
cross_entropy(p1, datatest$health)
```






